{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os \n",
    "import re \n",
    "import json\n",
    "import core\n",
    "import openai\n",
    "import config\n",
    "import pathlib\n",
    "import logging\n",
    "import requests\n",
    "import itertools  \n",
    "import numpy as np\n",
    "import transformers\n",
    "from typing import List\n",
    "from bs4 import BeautifulSoup \n",
    "from urllib.parse import urlparse, urljoin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# General Settings\n",
    "openai.api_type = \"azure\"\n",
    "openai.api_base = \"https://chatbotv2.openai.azure.com/\"\n",
    "openai.api_version = \"2022-06-01-preview\"\n",
    "openai.api_key = os.getenv(\"OPENAI_API_KEY_JW\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Connect2Seeking (trigger:bool) -> dict:\n",
    "    \"\"\" Connect to SeekAplha\n",
    "    Check Last News and Trading New\n",
    "    \n",
    "    Parameters:\n",
    "        trigger : bool, True to initiate Connection \n",
    "        \n",
    "    Return \n",
    "        tmp_container: dict {'latest-articles':{'article':'lnk'}, 'market-news':{'article':'lnk'}'\n",
    "        \n",
    "    \"\"\"\n",
    "    if not trigger:\n",
    "        return {}\n",
    "        \n",
    "    # Handle Error \n",
    "    try:\n",
    "        for section in core.Extension:\n",
    "            \n",
    "            # Initating Conection \n",
    "            with requests.session() as session:\n",
    "\n",
    "                req = session.get(urljoin(core.UrlBase, section))\n",
    "                req.raise_for_status()\n",
    "                bs = BeautifulSoup(req.content, \"html.parser\")\n",
    "\n",
    "                # Headers\n",
    "                tmp_key = list(core.Headers.keys())[0]\n",
    "                tmp_headers = bs.find(tmp_key, attrs = core.Headers[tmp_key])\n",
    "\n",
    "                # Creating tmp_container \n",
    "                if section not in core.TMP_CONTAINER.keys():\n",
    "                    core.TMP_CONTAINER[section] = {}\n",
    "\n",
    "                # Getting Articles\n",
    "                tmp_key_article = list(core.Target.keys())[0]\n",
    "                for article in tmp_headers.find_all(tmp_key_article, attrs=core.Target[tmp_key_article]):\n",
    "                    core.TMP_CONTAINER[section][article.text]= urljoin(core.UrlBase, article['href'])\n",
    "                    \n",
    "    except requests.exceptions.HTTPError as errh:\n",
    "        logging.error(\"HTTP Error:\", errh)\n",
    "    except requests.exceptions.ConnectionError as errc:\n",
    "        logging.error(\"Error Connecting:\", errc)\n",
    "    except requests.exceptions.Timeout as errt:\n",
    "        logging.error(\"Timeout Error:\", errt)\n",
    "    except requests.exceptions.RequestException as err:\n",
    "        logging.error(\"Something went wrong:\", err)\n",
    "    return core.TMP_CONTAINER\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['latest-articles', 'market-news'])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tmp_container = Connect2Seeking(True)\n",
    "tmp_container.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# =======================================\n",
    "# Process Document Step 1.\n",
    "# =======================================\n",
    "\n",
    "def ProcessingDocuments (string:str)-> List[tuple]:\n",
    "    \"\"\" Preprocess the Whole Article\n",
    "    Parameters:\n",
    "        string: Article Selected by User\n",
    "\n",
    "    Return:\n",
    "        article, List[(Article Section, Article Text)]\n",
    "    \"\"\"\n",
    "    # Parameters\n",
    "    Limit = 1000\n",
    "    end_index = 0\n",
    "    article = []\n",
    "\n",
    "    # Preprocessing Tokens\n",
    "    tmp_string = string # Copy\n",
    "    tokenizer = transformers.GPT2Tokenizer.from_pretrained(\"gpt2\", cache_dir = os.path.join(config.TOKENIZER_DIR, \"models--gpt2\"))\n",
    "    tokens = tokenizer.tokenize(tmp_string)\n",
    "    num_tokens = len(tokens)\n",
    "\n",
    "    if num_tokens > Limit:\n",
    "        # Splitting Document \n",
    "        for num, section in enumerate(range(0, num_tokens, Limit)):\n",
    "            end_index += section + Limit\n",
    "            article.append((f\"section_{num+1}\" , \"\".join(tokenizer.convert_tokens_to_string(tokens[section:end_index]))))\n",
    "    else:\n",
    "        article.append((f\"section_{num+1}\" , \"\".join(tokenizer.convert_tokens_to_string(tokens))))\n",
    "\n",
    "    return article\n",
    "\n",
    "# =======================================\n",
    "#  Document Ebeddings Step 2.\n",
    "# =======================================\n",
    "\n",
    "def DocEmbedding (corpus:tuple, save_at:str)->dict:\n",
    "    \"\"\" Connect to OpenAI\n",
    "    Transform page into embeddings\n",
    "    \n",
    "    Args:\n",
    "        corpus: tuple(section, text),\n",
    "        selected_option: option selected by user\n",
    "        \n",
    "    return:\n",
    "        dict, {'section_n': (article, floats -> Embeddings)}\n",
    "    \"\"\"\n",
    "\n",
    "    # Settings\n",
    "    EMBEDDINGS = {}\n",
    "    KEYS_ = core.DOC_KEYS\n",
    "    Keep_Server = core.BASE[1] if core.SERVER.lower() == openai.api_type else core.BASE[0]\n",
    "    core.QUESTION_PARAMS.pop(Keep_Server, None)\n",
    "\n",
    "    for section, txt in corpus:\n",
    "        txt = txt.replace(\"\\n\", \" \")\n",
    "        core.EMBEDDING_PARAMS['input'] = txt\n",
    "        embeddings = openai.Embedding.create(**core.EMBEDDING_PARAMS)\n",
    "        EMBEDDINGS[section] = (txt, embeddings[KEYS_[0]][0][KEYS_[1]])\n",
    "\n",
    "\n",
    "    # Saving Embeddings\n",
    "    with open(save_at, 'w', encoding='utf-8') as JsonSave:\n",
    "        json.dump(EMBEDDINGS,JsonSave, ensure_ascii=False)\n",
    "\n",
    "    return EMBEDDINGS\n",
    "\n",
    "# =======================================\n",
    "# Getting Article Step 3.\n",
    "# =======================================\n",
    "\n",
    "def GetArticle(Option:str, Selected:str)-> List[tuple]:\n",
    "    \"\"\" Connect to seeking Apha \n",
    "    Scrap and Transform Document \n",
    "    \n",
    "    Parameters:\n",
    "        Option : str, Latest, Trending\n",
    "        Selected: str, option selected by user\n",
    "        \n",
    "    Return \n",
    "        Article : pre-defined Message, List[(text, TotalTokens)] \"\"\"\n",
    "\n",
    "    # Parameters\n",
    "    Article_ = []\n",
    "    Limit = 1000\n",
    "\n",
    "    try:\n",
    "        tmp_file_name = re.sub(\"\\W+\",\"\",Selected)\n",
    "        save_at = os.path.join(config.EMBEDDINGS_DIR, f\"{tmp_file_name}.json\")\n",
    "\n",
    "        # Check if Document was Selected Before\n",
    "        if not os.path.isfile(save_at):\n",
    "\n",
    "            # Starting Connection \n",
    "            with requests.session() as session:\n",
    "                req = session.get(tmp_container[Option][Selected])\n",
    "                req.raise_for_status()\n",
    "                bs = BeautifulSoup(req.content, 'html.parser')\n",
    "\n",
    "                # Article \n",
    "                tmp_key_article = list(core.Article.keys())[0]\n",
    "                tmp_article = bs.find(tmp_key_article, attrs=core.Article[tmp_key_article]).text.strip()\n",
    "                    \n",
    "                # Preprocessing Tokens\n",
    "                tmp_section = ProcessingDocuments(tmp_article)\n",
    "\n",
    "                # Create Embeddings\n",
    "                Embedding = DocEmbedding(corpus = tmp_section, save_at=save_at)\n",
    "                Message_ =  \"Loading , This is my First Time Reading this Document\"\n",
    "        else:\n",
    "            # Load Doc &Embeddings\n",
    "            with open (save_at, mode= \"rb\") as JsonFile:\n",
    "                Embedding= json.load(JsonFile)\n",
    "\n",
    "            Message_ = \"It seems someone already asked me something about this article , Let me check\"\n",
    "    \n",
    "    except requests.exceptions.HTTPError as errh:\n",
    "        logging.error(\"HTTP Error:\", errh)\n",
    "    except requests.exceptions.ConnectionError as errc:\n",
    "        logging.error(\"Error Connecting:\", errc)\n",
    "    except requests.exceptions.Timeout as errt:\n",
    "        logging.error(\"Timeout Error:\", errt)\n",
    "    except requests.exceptions.RequestException as err:\n",
    "        logging.error(\"Something went wrong:\", err)\n",
    "\n",
    "\n",
    "    return Message_, Embedding\n",
    "\n",
    "# =======================================\n",
    "# Getting Question Embeddings Step 4.\n",
    "# =======================================\n",
    "\n",
    "def GetQuestionEmbedding(Question:str) -> np.array:\n",
    "    \"\"\" Connect to Open AI and Retrieve Query Embedding\n",
    "    Question : str, question given by user \" \n",
    "        \n",
    "    Return \n",
    "        np.array which is the QueryEmbedding\"\"\"\n",
    "\n",
    "    DICT_KEYS = core.DOC_KEYS\n",
    "    Keep_Server = core.BASE[1] if core.SERVER.lower() == openai.api_type else core.BASE[0]\n",
    "    core.QUESTION_PARAMS.pop(Keep_Server, None)\n",
    "    core.QUESTION_PARAMS['input'] = Question\n",
    "    \n",
    "    QuestionEmb = openai.Embedding.create(**core.QUESTION_PARAMS)\n",
    "    return np.array(QuestionEmb[DICT_KEYS[0]][0][DICT_KEYS[1]])\n",
    "\n",
    "# =======================================\n",
    "# Comparing Question and Article Step 5.\n",
    "# =======================================\n",
    "\n",
    "def ComparingQuestion(QuestionEmb, DocEmb) -> list:\n",
    "    \"\"\" Use Cosine Similarity to filter document Embeddings\n",
    "    Parameters:\n",
    "        QuestionEmb: Embedding representation from question,\n",
    "        DocEmb: Embedding representation from Document\n",
    "\n",
    "    Return\n",
    "        List with the higest doc Similiraty\n",
    "        (CosinSimilarity, Article Part, Text)\n",
    "    \"\"\"\n",
    "\n",
    "    DICT_KEYS = core.COMPARING_KEY\n",
    "    doc_similarity = (sorted([(np.dot(QuestionEmb, np.array(DocEmb[key_section][1])) , DocEmb[key_section][0]) for key_section in DocEmb.keys()],reverse= True))\n",
    "\n",
    "    return doc_similarity\n",
    "\n",
    "# =======================================\n",
    "# Asking Chatbot Step 6.\n",
    "# =======================================\n",
    "\n",
    "def SendingQuestion(Question:str, Mode:str, Doc:str)-> str:\n",
    "\n",
    "    DICT_KEYS = core.ANSWER_KEYS\n",
    "    Keep_Server = core.BASE[1] if core.SERVER.lower() == openai.api_type else core.BASE[0]\n",
    "    core.ANSWER_PARAMS.pop(Keep_Server, None)\n",
    "\n",
    "    # OpenChatModel\n",
    "    if Mode == core.OPTIONS_MODE[0]:\n",
    "        Statement = core.HEADERS[0] + Doc[1] + core.QATOKENS[0] + Question + core.QATOKENS[3] + core.QATOKENS[1] \n",
    "        core.ANSWER_PARAMS['prompt'] = Statement\n",
    "        _response = openai.Completion.create(**core.ANSWER_PARAMS)\n",
    "\n",
    "    elif Mode == core.OPTIONS_MODE[1]:\n",
    "        Statement = core.HEADERS[1] + Doc + core.QATOKENS[2]\n",
    "        core.ANSWER_PARAMS['prompt'] = Statement\n",
    "        _response = openai.Completion.create(**core.ANSWER_PARAMS)\n",
    "\n",
    "    return _response[DICT_KEYS[0]][0][DICT_KEYS[1]].strip(\" \\n\")\n",
    "\n",
    "\n",
    "def UserQuestion (Question:str, Option:str, Article:str, Mode:str='OpenChatbot' )-> str:\n",
    "    \"\"\" Query Question and Initiate Chatbot\n",
    "    Parameters:\n",
    "        Question : str, Question given by the user\n",
    "        Option: str, latest-articles | market-news\n",
    "        Mode : OpenChatbot : Free Question, Summary : Create Summary only\n",
    "    \"\"\"\n",
    "\n",
    "    # Load The Article \n",
    "    Doc, Stop = None , 0\n",
    "    Message, ArticleSelected = GetArticle(Option,Article)\n",
    "    \n",
    "    # OpenChatbot\n",
    "    if Mode == core.OPTIONS_MODE[0]:\n",
    "        EmbQuestion = GetQuestionEmbedding(Question)\n",
    "        Top_Realted = ComparingQuestion(EmbQuestion,ArticleSelected)\n",
    "        Doc = Top_Realted[0]\n",
    "\n",
    "    # Summary\n",
    "    if Mode == core.OPTIONS_MODE[1]:\n",
    "        Doc = \"\".join([text for _, (text, score) in itertools.islice(sorted(ArticleSelected.items(), key=lambda x: x[1][0]), 2)])\n",
    "        \n",
    "    Answer = SendingQuestion(Question, Mode = Mode, Doc = Doc)\n",
    "    return Message, Answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "('It seems someone already asked me something about this article , Let me check',\n",
       " 'The S&P 500 is testing very important technical resistance and looks to be making a bullish breakout following the positive CPI report last week.')"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "art = UserQuestion (\"how is the daily chart breaking\",\n",
    "Option='latest-articles',\n",
    "Article=\"S&P 500: On The Verge Of A Bullish Breakout - Week Starting Feb. 16th (Technical Analysis)\") \n",
    "print(\"----------\")\n",
    "art"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "32fec40cd58b30964898a2316b7a6c6cca3b94bb6c135d58a9097c7356976a0a"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
